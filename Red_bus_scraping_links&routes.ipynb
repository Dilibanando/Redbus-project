{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a87dd0-a6fb-413e-83ca-f110e7a21193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize WebDriver (assuming you have set up the WebDriver for your browser)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "def navigate_to_page(page_number):\n",
    "    \"\"\"\n",
    "    Navigate to the specified page number within the pagination table.\n",
    "    \n",
    "    Args:\n",
    "        page_number (int): The page number to navigate to.\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if navigation to the page was successful, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Wait for the pagination table to be present\n",
    "        pagination_table = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'DC_117_paginationTable')))\n",
    "        \n",
    "        # Find all page tabs within the pagination table\n",
    "        page_tabs = pagination_table.find_elements(By.CLASS_NAME, 'DC_117_pageTabs')\n",
    "        \n",
    "        # Loop through each page tab to find the one with the correct text\n",
    "        for tab in page_tabs:\n",
    "            if tab.text.strip() == str(page_number):\n",
    "                # Using ActionChains to click on the page tab\n",
    "                ActionChains(driver).move_to_element(tab).click().perform()\n",
    "                \n",
    "                # Wait for elements with class=\"route\" and href attributes to be present on the new page\n",
    "                WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'a.route[href]')))\n",
    "                return True  # Return True if successfully navigated to the page\n",
    "        return False  # Return False if page number is not found\n",
    "    except Exception as e:\n",
    "        print(f\"Error navigating to page {page_number}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# List of URLs to scrape bus data from\n",
    "bus_links_dfs = [\n",
    "    \"https://www.redbus.in/online-booking/ktcl/?utm_source=rtchometil\",\n",
    "    \"https://www.redbus.in/online-booking/tsrtc/?utm_source=rtchometile\",\n",
    "    \"https://www.redbus.in/online-booking/chandigarh-transport-undertaking-ctu\",\n",
    "    \"https://www.redbus.in/online-booking/pepsu/?utm_source=rtchometile\",\n",
    "    \"https://www.redbus.in/online-booking/wbtc-ctc\",\n",
    "    \"https://www.redbus.in/online-booking/apsrtc\",\n",
    "    \"https://www.redbus.in/online-booking/ksrtc-kerala\",\n",
    "    \"https://www.redbus.in/online-booking/rsrtc\",\n",
    "    \"https://www.redbus.in/online-booking/astc\",\n",
    "    \"https://www.redbus.in/online-booking/meghalaya-transport-corporation-mtc\"\n",
    "]\n",
    "\n",
    "# Variable names for DataFrames to store bus route data\n",
    "bus_routes_dfs = [\"df_kt\", \"df_t\", \"df_ch\", \"df_pu\", \"df_wb\", \"df_ap\", \"df_kr\", \"df_rj\", \"df_as\", \"df_mg\"]\n",
    "\n",
    "try:\n",
    "    \"\"\"\n",
    "    Main block to scrape bus data from multiple URLs, navigate through pagination,\n",
    "    and store the scraped data into corresponding DataFrames.\n",
    "    \"\"\"\n",
    "    for idx, url in enumerate(bus_links_dfs):\n",
    "        # Load the initial webpage\n",
    "        driver.get(url)\n",
    "        driver.maximize_window()\n",
    "\n",
    "        # Wait for elements with class=\"route\" and href attributes to be present\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'a.route[href]')))\n",
    "\n",
    "        # Initialize lists to store data\n",
    "        bus_links = []\n",
    "        bus_routes = []\n",
    "\n",
    "        # Wait for the pagination table to be present\n",
    "        pagination_table = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'DC_117_paginationTable')))\n",
    "        \n",
    "        # Get all page numbers\n",
    "        page_tabs = pagination_table.find_elements(By.CLASS_NAME, 'DC_117_pageTabs')\n",
    "        page_numbers = [tab.text.strip() for tab in page_tabs]\n",
    "\n",
    "        # Loop through each page\n",
    "        for page_number in page_numbers:\n",
    "            # Navigate to the specified page\n",
    "            if navigate_to_page(page_number):\n",
    "                # Find all elements with both class=\"route\" and href attributes\n",
    "                elements = driver.find_elements(By.CSS_SELECTOR, 'a.route[href]')\n",
    "                \n",
    "                # Loop through each element found\n",
    "                for element in elements:\n",
    "                    href_value = element.get_attribute('href')\n",
    "                    class_value = element.get_attribute('title')\n",
    "                    bus_links.append(href_value)\n",
    "                    bus_routes.append(class_value)\n",
    "                    print(f\"bus_link: {href_value}, bus_route: {class_value}\")\n",
    "            else:\n",
    "                print(f\"Failed to navigate to page {page_number}\")\n",
    "\n",
    "        # Create a DataFrame from the lists and store it in the corresponding variable\n",
    "        globals()[bus_routes_dfs[idx]] = pd.DataFrame({\n",
    "            'bus_link': bus_links,\n",
    "            'bus_route': bus_routes\n",
    "        })\n",
    "\n",
    "finally:\n",
    "    \"\"\"\n",
    "    Ensure that the WebDriver is closed properly after the scraping is complete.\n",
    "    \"\"\"\n",
    "    driver.quit()\n",
    "\n",
    "# Print DataFrames to check the data\n",
    "for df_name in bus_routes_dfs:\n",
    "    print(globals()[df_name])\n",
    "\n",
    "# Save DataFrames to CSV (if needed)\n",
    "for idx, df_name in enumerate(bus_routes_dfs):\n",
    "    globals()[df_name].to_csv(f'bus_routes_{df_name}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dfd938a-d741-4afa-ba4f-e27af33ddeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all individual DataFrames into a single DataFrame\n",
    "# This combines data from multiple sources into one DataFrame for easier analysis.\n",
    "df_concatinated_data = pd.concat([df_kt, df_t, df_ch, df_pu, df_wb, df_ap, df_kr, df_rj, df_as, df_mg], ignore_index=True)\n",
    "\n",
    "# Print the column names of the concatenated DataFrame to verify\n",
    "df_concatinated_data.columns\n",
    "\n",
    "# Save the concatenated DataFrame to a CSV file\n",
    "# This file will contain all the scraped data combined into a single CSV file.\n",
    "df_concatinated_data.to_csv('redbus_scarped_datas_routes_links.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10770e4d-8660-4a13-a177-02454a4563ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
